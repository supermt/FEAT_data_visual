Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
/home/supermt/rocksdb_hdd
Keys:       10 bytes each
Values:     1000 bytes each (500 bytes after compression)
Entries:    48318382
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    46540.8 MB (estimated)
FileSize:   23500.8 MB (estimated)
Write rate: 0 bytes/second
Read rate: 0 ops/second
Compression: NoCompression
Compression sampling rate: 0
Memtablerep: skip_list
Perf Level: 1
------------------------------------------------
0 point(s) detected
use the FEAT tuner 
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
/home/supermt/rocksdb_hdd
DB path: [/home/supermt/rocksdb_hdd]
using reporter agent with change points.
Using FEAT tuner.
 FEA is triggered
TEA is triggered
insert start:0
record count:60000000
op count:60000000
new keys:0
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
idle threads, decrease thread
idle threads, reduce batch
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flush, decrease thread
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flush, decrease thread
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
ycsb_load    :      34.122 micros/op 29306 ops/sec;   28.6 MB/s
Microseconds per write:
Count: 60000000 Average: 34.1219  StdDev: 61.38
Min: 2  Median: 3.6930  Max: 163931690
Percentiles: P50: 3.69 P75: 5.03 P99: 48.81 P99.9: 1247.06 P99.99: 1295.25
------------------------------------------------------
(       1,       2 ]   352855   0.588%   0.588% 
(       2,       3 ] 15279785  25.466%  26.054% #####
(       3,       4 ] 20731403  34.552%  60.607% #######
(       4,       6 ] 16785622  27.976%  88.583% ######
(       6,      10 ]  2086029   3.477%  92.059% #
(      10,      15 ]  1180573   1.968%  94.027% 
(      15,      22 ]  2033938   3.390%  97.417% #
(      22,      34 ]   647244   1.079%  98.496% 
(      34,      51 ]   347305   0.579%  99.075% 
(      51,      76 ]    72124   0.120%  99.195% 
(      76,     110 ]      375   0.001%  99.195% 
(     110,     170 ]       53   0.000%  99.196% 
(     170,     250 ]       33   0.000%  99.196% 
(     250,     380 ]       44   0.000%  99.196% 
(     380,     580 ]       16   0.000%  99.196% 
(     580,     870 ]        4   0.000%  99.196% 
(     870,    1300 ]   481925   0.803%  99.999% 
(    1300,    1900 ]      163   0.000%  99.999% 
(    1900,    2900 ]      116   0.000%  99.999% 
(    2900,    4400 ]       22   0.000%  99.999% 
(    4400,    6600 ]       13   0.000%  99.999% 
(    6600,    9900 ]        9   0.000%  99.999% 
(    9900,   14000 ]        5   0.000%  99.999% 
(   14000,   22000 ]       13   0.000%  99.999% 
(   22000,   33000 ]       12   0.000%  99.999% 
(   33000,   50000 ]       14   0.000%  99.999% 
(   50000,   75000 ]       24   0.000% 100.000% 
(   75000,  110000 ]       26   0.000% 100.000% 
(  110000,  170000 ]       16   0.000% 100.000% 
(  170000,  250000 ]       21   0.000% 100.000% 
(  250000,  380000 ]       48   0.000% 100.000% 
(  380000,  570000 ]       57   0.000% 100.000% 
(  570000,  860000 ]       19   0.000% 100.000% 
(  860000, 1200000 ]        5   0.000% 100.000% 
( 1200000, 1900000 ]        4   0.000% 100.000% 
( 1900000, 2900000 ]        5   0.000% 100.000% 
( 2900000, 4300000 ]       12   0.000% 100.000% 
( 4300000, 6500000 ]       27   0.000% 100.000% 
( 6500000, 9800000 ]       23   0.000% 100.000% 
( 9800000, 14000000 ]        4   0.000% 100.000% 
( 14000000, 22000000 ]        6   0.000% 100.000% 
( 22000000, 33000000 ]        1   0.000% 100.000% 
( 33000000, 49000000 ]        3   0.000% 100.000% 
( 49000000, 74000000 ]        2   0.000% 100.000% 
( 74000000, 110000000 ]        1   0.000% 100.000% 
( 160000000, 250000000 ]        1   0.000% 100.000% 

DB path: [/home/supermt/rocksdb_hdd]
using reporter agent with change points.
Using FEAT tuner.
 FEA is triggered
TEA is triggered
insert start:0
record count:60000000
op count:60000000
new keys:0
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flush, decrease thread
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flushing, increase batch
slow flush, decrease thread
slow flushing, increase batch
slow flush, decrease thread
slow flush, decrease thread
slow flush, decrease thread
slow flush, decrease thread
ycsb_run     :      67.748 micros/op 14760 ops/sec;    7.2 MB/s
Microseconds per read:
Count: 26565845 Average: 105.9947  StdDev: 25.89
Min: 0  Median: 9.5344  Max: 1603492
Percentiles: P50: 9.53 P75: 14.31 P99: 73.64 P99.9: 13887.38 P99.99: 85873.25
------------------------------------------------------
[       0,       1 ]  1346189   5.067%   5.067% #
(       1,       2 ]  4392659  16.535%  21.602% ###
(       2,       3 ]  2274936   8.563%  30.166% ##
(       3,       4 ]   812346   3.058%  33.224% #
(       4,       6 ]  1182792   4.452%  37.676% #
(       6,      10 ]  3705284  13.948%  51.623% ###
(      10,      15 ]  7199598  27.101%  78.724% #####
(      15,      22 ]  2113859   7.957%  86.681% ##
(      22,      34 ]  2492122   9.381%  96.062% ##
(      34,      51 ]   568291   2.139%  98.202% 
(      51,      76 ]   234217   0.882%  99.083% 
(      76,     110 ]    69885   0.263%  99.346% 
(     110,     170 ]     7330   0.028%  99.374% 
(     170,     250 ]      247   0.001%  99.375% 
(     250,     380 ]      214   0.001%  99.376% 
(     380,     580 ]       27   0.000%  99.376% 
(     580,     870 ]       28   0.000%  99.376% 
(     870,    1300 ]        4   0.000%  99.376% 
(    1300,    1900 ]       45   0.000%  99.376% 
(    1900,    2900 ]      804   0.003%  99.379% 
(    2900,    4400 ]     5828   0.022%  99.401% 
(    4400,    6600 ]    20869   0.079%  99.480% 
(    6600,    9900 ]    56158   0.211%  99.691% 
(    9900,   14000 ]    57116   0.215%  99.906% 
(   14000,   22000 ]    15455   0.058%  99.964% 
(   22000,   33000 ]     3209   0.012%  99.976% 
(   33000,   50000 ]     1797   0.007%  99.983% 
(   50000,   75000 ]     1643   0.006%  99.989% 
(   75000,  110000 ]      761   0.003%  99.992% 
(  110000,  170000 ]      657   0.002%  99.994% 
(  170000,  250000 ]      527   0.002%  99.996% 
(  250000,  380000 ]      502   0.002%  99.998% 
(  380000,  570000 ]      281   0.001%  99.999% 
(  570000,  860000 ]       74   0.000% 100.000% 
(  860000, 1200000 ]       27   0.000% 100.000% 
( 1200000, 1900000 ]       64   0.000% 100.000% 

Microseconds per update:
Count: 26573154 Average: 29.5110  StdDev: 72.28
Min: 2  Median: 4.6168  Max: 71296623
Percentiles: P50: 4.62 P75: 8.33 P99: 61.44 P99.9: 1227.22 P99.99: 1293.57
------------------------------------------------------
(       1,       2 ]    20474   0.077%   0.077% 
(       2,       3 ]  2849288  10.722%  10.799% ##
(       3,       4 ]  7916427  29.791%  40.591% ######
(       4,       6 ]  8107858  30.511%  71.102% ######
(       6,      10 ]  1780345   6.700%  77.802% #
(      10,      15 ]  1498795   5.640%  83.442% #
(      15,      22 ]  2947843  11.093%  94.535% ##
(      22,      34 ]   957843   3.605%  98.140% #
(      34,      51 ]   172416   0.649%  98.789% 
(      51,      76 ]   134371   0.506%  99.294% 
(      76,     110 ]    30167   0.114%  99.408% 
(     110,     170 ]     1729   0.007%  99.414% 
(     170,     250 ]       78   0.000%  99.415% 
(     250,     380 ]       25   0.000%  99.415% 
(     380,     580 ]       87   0.000%  99.415% 
(     580,     870 ]       90   0.000%  99.416% 
(     870,    1300 ]   154977   0.583%  99.999% 
(    1300,    1900 ]       28   0.000%  99.999% 
(    1900,    2900 ]       34   0.000%  99.999% 
(    2900,    4400 ]       19   0.000%  99.999% 
(    4400,    6600 ]        8   0.000%  99.999% 
(    6600,    9900 ]        6   0.000%  99.999% 
(    9900,   14000 ]       11   0.000%  99.999% 
(   14000,   22000 ]       12   0.000%  99.999% 
(   22000,   33000 ]       10   0.000%  99.999% 
(   33000,   50000 ]       14   0.000%  99.999% 
(   50000,   75000 ]       21   0.000%  99.999% 
(   75000,  110000 ]       28   0.000%  99.999% 
(  110000,  170000 ]       24   0.000% 100.000% 
(  170000,  250000 ]       12   0.000% 100.000% 
(  250000,  380000 ]       32   0.000% 100.000% 
(  380000,  570000 ]       32   0.000% 100.000% 
(  570000,  860000 ]       16   0.000% 100.000% 
(  860000, 1200000 ]        7   0.000% 100.000% 
( 1200000, 1900000 ]        6   0.000% 100.000% 
( 1900000, 2900000 ]        2   0.000% 100.000% 
( 2900000, 4300000 ]        5   0.000% 100.000% 
( 4300000, 6500000 ]        6   0.000% 100.000% 
( 6500000, 9800000 ]        3   0.000% 100.000% 
( 14000000, 22000000 ]        1   0.000% 100.000% 
( 33000000, 49000000 ]        1   0.000% 100.000% 
( 49000000, 74000000 ]        3   0.000% 100.000% 



** Compaction Stats [default] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  L0      1/0   296.85 MB   0.2      8.2     0.0      8.2      80.3     72.1       0.0   1.1      4.0     39.8   2062.88            233.69       176   11.721   8426K   871K
  L1     12/0    1.91 GB   1.0    131.3    71.8     59.5     127.9     68.4       0.0   1.8     81.8     79.6   1644.44            262.21        18   91.358    135M  3458K
  L2     57/0   19.46 GB   1.0    154.2    63.5     90.7     151.3     60.7       3.0   2.4     19.1     18.7   8282.19            436.70       131   63.223    159M  2913K
  L3     96/0   43.53 GB   0.2     20.5    10.7      9.9      19.8     10.0      33.6   1.9     14.3     13.9   1464.86             67.11        19   77.098     21M   725K
 Sum    166/0   65.18 GB   0.0    314.1   146.0    168.2     379.3    211.1      36.6   5.2     23.9     28.9  13454.37            999.72       344   39.112    324M  7968K
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.3      0.3       0.0   1.0      0.0     76.4      3.88              0.85         1    3.885       0      0

** Compaction Stats [default] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Low      0/0    0.00 KB   0.0    314.1   146.0    168.2     306.4    138.2       0.0   0.0     27.6     26.9  11666.52            784.64       175   66.666    324M  7968K
High      0/0    0.00 KB   0.0      0.0     0.0      0.0      72.9     72.9       0.0   0.0      0.0     41.8   1787.85            215.08       169   10.579       0      0
Uptime(secs): 5647.7 total, 247.7 interval
Flush(GB): cumulative 72.947, interval 0.290
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 379.31 GB write, 68.77 MB/s write, 314.12 GB read, 56.95 MB/s read, 13454.4 seconds
Interval compaction: 0.29 GB write, 1.20 MB/s write, 0.00 GB read, 0.00 MB/s read, 3.9 seconds
Stalls(count): 21 level0_slowdown, 21 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 40 slowdown for pending_compaction_bytes, 337 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level (Include Compaction) [default] **

** File Read Latency Histogram By Level (Without Compaction) [default] **

** DB Stats **
Uptime(secs): 5647.7 total, 247.7 interval
Cumulative writes: 86M writes, 86M keys, 86M commit groups, 1.0 writes per commit group, ingest: 83.80 GB, 15.19 MB/s
Cumulative WAL: 86M writes, 0 syncs, 86573154.00 writes per sync, written: 83.80 GB, 15.19 MB/s
Cumulative stall: 00:34:58.320 H:M:S, 37.2 percent
Cumulative L0 stall: 00:07:15.934 H:M:S
Cumulative Mem stall: 00:21:10.992 H:M:S
Cumulative Pending stall: 00:06:31.393 H:M:S
Interval writes: 681K writes, 681K keys, 681K commit groups, 1.0 writes per commit group, ingest: 675.37 MB, 2.73 MB/s
Interval WAL: 681K writes, 0 syncs, 681309.00 writes per sync, written: 0.66 MB, 2.73 MB/s
Interval stall: 00:00:0.000 H:M:S, 0.0 percent
Interval L0 stall: 00:00:0.000 H:M:S
Interval Mem stall: 00:00:0.000 H:M:S
Interval Pending stall: 00:00:0.000 H:M:S

